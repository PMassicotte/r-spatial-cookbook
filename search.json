[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "R Spatial Cookbook",
    "section": "",
    "text": "About this book\nThis book serves as a personal reference. It is intended to help me remember the techniques for manipulating spatial data in R.",
    "crumbs": [
      "About this book"
    ]
  },
  {
    "objectID": "chapters/importing/01_binary_format.html",
    "href": "chapters/importing/01_binary_format.html",
    "title": "1  Binary format",
    "section": "",
    "text": "1.1 NSIDC binary data\nBinary data is a format where information is stored in a sequence of bytes, representing data in its most basic form without any text-based structure. This format is efficient for storage and quick to read programmatically, but it’s not human-readable without proper interpretation. In the case of scientific datasets like sea ice concentration, binary formats were often used to minimize file size and optimize data processing speed.\nBased on the documentation, the binary files can be read using the following code:\nsic &lt;- readBin(\n  here::here(\"data\", \"nsidc\", \"nt_20171002_f17_v1.1_n.bin\"),\n  what = \"integer\",\n  n = 304L * 448L,\n  size = 1L,\n  signed = FALSE\n)\n\n\nlat &lt;- readBin(\n  here::here(\"data\", \"nsidc\", \"psn25lats_v3.dat\"),\n  what = \"integer\",\n  n = 304L * 448L,\n  size = 4L,\n  signed = TRUE\n)\n\nlon &lt;- readBin(\n  here::here(\"data\", \"nsidc\", \"psn25lons_v3.dat\"),\n  what = \"integer\",\n  n = 304L * 448L,\n  size = 4L,\n  signed = TRUE\n)\nWe can construct a data frame from the latitude, longitude, and sea ice concentration data:\ndf &lt;- data.frame(lat = lat / 100000L, lon = lon / 100000L, sic = sic)\n\nhead(df)\n\n\n\n\n\nlat\nlon\nsic\n\n\n\n\n31.10267\n168.3204\n48\n\n\n31.19941\n168.1488\n48\n\n\n31.29580\n167.9764\n50\n\n\n31.39183\n167.8034\n53\n\n\n31.48750\n167.6297\n53\n\n\n31.58280\n167.4553\n0\n\n\n\n\n\nrange(df[[\"sic\"]], na.rm = TRUE)\n\n[1]   0 254\nAccording to the documentation:",
    "crumbs": [
      "Importing",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Binary format</span>"
    ]
  },
  {
    "objectID": "chapters/importing/01_binary_format.html#nsidc-binary-data",
    "href": "chapters/importing/01_binary_format.html#nsidc-binary-data",
    "title": "1  Binary format",
    "section": "",
    "text": "Note\n\n\n\nVersion 1 of the NSIDC-0081 sea ice concentration dataset is available in binary format but is no longer active. The current version (Version 2) is in NetCDF format.\n\n\n\n\n\n\n\n\nThe sea ice concentration floating-point values (fractional coverage ranging from 0.0 to 1.0) are multiplied by a scaling factor of 250. To convert to the fractional range of 0.0 to 1.0, divide the scaled data in the file by 250.\n\n\n\n\n\n\n\n\nData Value\nDescription\n\n\n\n\n0 - 250\nSea ice concentration (fractional coverage scaled by 250)\n\n\n251\nCircular mask used in the Arctic to cover the irregularly-shaped data gap around the pole (caused by the orbit inclination and instrument swath)\n\n\n252\nUnused\n\n\n253\nCoast\n\n\n254\nLand\n\n\n255\nMissing data\n\n\n\n\n1.1.1 Conversion to raster\nWe can turn the data into a raster object using the terra package. The sea ice concentration values are stored in a 448x304 matrix, which we can convert to a raster object.\n\nsic_matrix &lt;- matrix(sic, nrow = 448L, ncol = 304L, byrow = TRUE)\n\nr &lt;- rast(sic_matrix)\n\nplot(r)\n\n\n\n\n\n\n\next(r) &lt;- c(-3850000L, 3750000L, -5350000L, 5850000L)\ncrs(r) &lt;- \"+proj=stere +lat_0=90 +lat_ts=70 +lon_0=-45 +k=1 +x_0=0 +y_0=0 +datum=WGS84 +units=m +no_defs\"\n\nplot(r)",
    "crumbs": [
      "Importing",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Binary format</span>"
    ]
  },
  {
    "objectID": "chapters/importing/02_hdf4.html",
    "href": "chapters/importing/02_hdf4.html",
    "title": "2  HDF4 format",
    "section": "",
    "text": "2.1 NetCDF (Network Common Data Form)\nLayers in the file can be listed using the nc_open() function:\nfile &lt;- here::here(\"data\", \"avhrr-only-v2.20160503.nc\")",
    "crumbs": [
      "Importing",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>HDF4 format</span>"
    ]
  },
  {
    "objectID": "chapters/importing/02_hdf4.html#netcdf-network-common-data-form",
    "href": "chapters/importing/02_hdf4.html#netcdf-network-common-data-form",
    "title": "2  HDF4 format",
    "section": "",
    "text": "2.1.1 Open NetCDF file using rast()\nThe terra package provides an alternative method to work with NetCDF files. This creates a SpatRaster object, which is more memory-efficient for large datasets.\nTo see which layers are available in the file, use the describe() function. Note the var column in the output:\n\ndescribe(file, sds = TRUE)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nid\nname\nvar\ndesc\nnrow\nncol\nnlyr\n\n\n\n\n1\nNETCDF:“/media/LaCie16TB/work/projects/documentation/read_rs_product/data/avhrr-only-v2.20160503.nc”:sst\nsst\n[1x1x720x1440] sst (16-bit integer)\n720\n1440\n1\n\n\n2\nNETCDF:“/media/LaCie16TB/work/projects/documentation/read_rs_product/data/avhrr-only-v2.20160503.nc”:anom\nanom\n[1x1x720x1440] anom (16-bit integer)\n720\n1440\n1\n\n\n3\nNETCDF:“/media/LaCie16TB/work/projects/documentation/read_rs_product/data/avhrr-only-v2.20160503.nc”:err\nerr\n[1x1x720x1440] err (16-bit integer)\n720\n1440\n1\n\n\n4\nNETCDF:“/media/LaCie16TB/work/projects/documentation/read_rs_product/data/avhrr-only-v2.20160503.nc”:ice\nice\n[1x1x720x1440] ice (16-bit integer)\n720\n1440\n1\n\n\n\n\n\n\nThis file contains four layers: sst, anom, err, and ice. They can be opened using the rast() function using the lyrs or subds argument.\n\n\n\n\n\n\nNote\n\n\n\nTODO: Explain the difference between lyrs and subds.\n\n\n\n2.1.1.1 Open a specific layer using lyrs\n\n# To open the sst layer\nsst_layer &lt;- rast(paste0(\"NETCDF:\", file, \":sst\"))\n\n# To open the anom layer\nanom_layer &lt;- rast(paste0(\"NETCDF:\", file, \":anom\"))\n\n# To open the err layer\nerr_layer &lt;- rast(paste0(\"NETCDF:\", file, \":err\"))\n\n# To open the ice layer\nice_layer &lt;- rast(paste0(\"NETCDF:\", file, \":ice\"))\n\n\n\n2.1.1.2 Open a specific layer using subds\n\n# To open the sst layer\nsst_layer &lt;- rast(file, subds = \"sst\")\n\n# To open the anom layer\nanom_layer &lt;- rast(file, subds = \"anom\")\n\n# To open the err layer\nerr_layer &lt;- rast(file, subds = \"err\")\n\n# Open the ice layer\nice_layer &lt;- rast(file, subds = \"ice\")\n\n\n\n\n2.1.2 Plotting\nWe can visualize the layers using the plot() function:\n\npar(mfrow = c(2L, 2L))\nplot(sst_layer, main = \"SST\")\nplot(anom_layer, main = \"Anomaly\")\nplot(err_layer, main = \"Error\")\nplot(ice_layer, main = \"Ice\")\n\n\n\n\n\n\n\n\nIt looks like the raster is rotated. We can rotate it back with the rotate() function:\n\nsst_layer &lt;- rotate(sst_layer)\n\nplot(sst_layer)\n\n\n\n\n\n\n\n\nConverting to a data frame can be useful for certain types of analysis or visualization, but be cautious with large datasets as this can be memory-intensive.\n\ndf &lt;- as.data.frame(sst_layer)\n\nhead(df)\n\n\n\n\n\nsst_zlev=0\n\n\n\n\n-1.7\n\n\n-1.7\n\n\n-1.7\n\n\n-1.7\n\n\n-1.7\n\n\n-1.7",
    "crumbs": [
      "Importing",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>HDF4 format</span>"
    ]
  },
  {
    "objectID": "chapters/importing/03_he5.html",
    "href": "chapters/importing/03_he5.html",
    "title": "3  HE5 format",
    "section": "",
    "text": "3.1 Using terra directly\nThis section demonstrates how to access and visualize sea ice concentration data stored in HE5 files, focusing on data from the AMSR-E/AMSR2 Unified L3 Daily 12.5 km dataset. We’ll use R along with the gdalraster, stars, terra, and sf packages.\nThe code leverages the NetCDF interface to access subdatasets within the HE5 file. This allows us to access the geolocation arrays, which is crucial for proper spatial referencing.\nThe data needs to be transformed to a standard coordinate reference system (CRS). EPSG:3411 (NSIDC Sea Ice Polar Stereographic North) is commonly used for Northern Hemisphere sea ice data. The gdal_utils() function warps the data to this CRS and saves it to a temporary VRT (Virtual Raster) file. VRT files are useful because they act as a pointer to the original data without duplicating it, and allow for on-the-fly transformations.\nThe rast() function from the terra package is used to read the VRT file and create a SpatRaster object. This object contains the sea ice concentration data, which can be visualized using the plot() function.\nThe installed version of gdal can be checked with the following command:\ngdalinfo --version\n\nGDAL 3.10.1, released 2025/01/08 (debug build)\nIf you have a recent version of gdal, you read the data directly from the HE5 file with the terra package.\nvar_names &lt;- describe(file, sds = TRUE)\n\nhead(var_names)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nid\nname\nvar\ndesc\nnrow\nncol\nnlyr\n\n\n\n\n1\nHDF5:“/media/LaCie16TB/work/projects/documentation/read_rs_product/data/AMSR_U2_L3_SeaIce12km_B04_20140314.he5”://HDFEOS/GRIDS/NpPolarGrid12km/Data_Fields/SI_12km_NH_18H_ASC\n//HDFEOS/GRIDS/NpPolarGrid12km/Data_Fields/SI_12km_NH_18H_ASC\n[896x608] //HDFEOS/GRIDS/NpPolarGrid12km/Data_Fields/SI_12km_NH_18H_ASC (32-bit integer)\n896\n608\n1\n\n\n2\nHDF5:“/media/LaCie16TB/work/projects/documentation/read_rs_product/data/AMSR_U2_L3_SeaIce12km_B04_20140314.he5”://HDFEOS/GRIDS/NpPolarGrid12km/Data_Fields/SI_12km_NH_18H_DAY\n//HDFEOS/GRIDS/NpPolarGrid12km/Data_Fields/SI_12km_NH_18H_DAY\n[896x608] //HDFEOS/GRIDS/NpPolarGrid12km/Data_Fields/SI_12km_NH_18H_DAY (32-bit integer)\n896\n608\n1\n\n\n3\nHDF5:“/media/LaCie16TB/work/projects/documentation/read_rs_product/data/AMSR_U2_L3_SeaIce12km_B04_20140314.he5”://HDFEOS/GRIDS/NpPolarGrid12km/Data_Fields/SI_12km_NH_18H_DSC\n//HDFEOS/GRIDS/NpPolarGrid12km/Data_Fields/SI_12km_NH_18H_DSC\n[896x608] //HDFEOS/GRIDS/NpPolarGrid12km/Data_Fields/SI_12km_NH_18H_DSC (32-bit integer)\n896\n608\n1\n\n\n4\nHDF5:“/media/LaCie16TB/work/projects/documentation/read_rs_product/data/AMSR_U2_L3_SeaIce12km_B04_20140314.he5”://HDFEOS/GRIDS/NpPolarGrid12km/Data_Fields/SI_12km_NH_18V_ASC\n//HDFEOS/GRIDS/NpPolarGrid12km/Data_Fields/SI_12km_NH_18V_ASC\n[896x608] //HDFEOS/GRIDS/NpPolarGrid12km/Data_Fields/SI_12km_NH_18V_ASC (32-bit integer)\n896\n608\n1\n\n\n5\nHDF5:“/media/LaCie16TB/work/projects/documentation/read_rs_product/data/AMSR_U2_L3_SeaIce12km_B04_20140314.he5”://HDFEOS/GRIDS/NpPolarGrid12km/Data_Fields/SI_12km_NH_18V_DAY\n//HDFEOS/GRIDS/NpPolarGrid12km/Data_Fields/SI_12km_NH_18V_DAY\n[896x608] //HDFEOS/GRIDS/NpPolarGrid12km/Data_Fields/SI_12km_NH_18V_DAY (32-bit integer)\n896\n608\n1\n\n\n6\nHDF5:“/media/LaCie16TB/work/projects/documentation/read_rs_product/data/AMSR_U2_L3_SeaIce12km_B04_20140314.he5”://HDFEOS/GRIDS/NpPolarGrid12km/Data_Fields/SI_12km_NH_18V_DSC\n//HDFEOS/GRIDS/NpPolarGrid12km/Data_Fields/SI_12km_NH_18V_DSC\n[896x608] //HDFEOS/GRIDS/NpPolarGrid12km/Data_Fields/SI_12km_NH_18V_DSC (32-bit integer)\n896\n608\n1\n\n\n\n\n\nlayer &lt;- var_names[[\"var\"]][grepl(\"SI_12km_NH_ICECON_DAY\", var_names[[\"var\"]], fixed = TRUE)]\n\nlayer\n\n[1] \"//HDFEOS/GRIDS/NpPolarGrid12km/Data_Fields/SI_12km_NH_ICECON_DAY\"\n\nice_layer &lt;- rast(file, subds = layer)\n\nice_layer\n\nclass       : SpatRaster \ndimensions  : 896, 608, 1  (nrow, ncol, nlyr)\nresolution  : 12500, 12500  (x, y)\nextent      : -3850000, 3750000, -5350000, 5850000  (xmin, xmax, ymin, ymax)\ncoord. ref. : +proj=stere +lat_0=90 +lat_ts=70 +lon_0=-45 +x_0=0 +y_0=0 +R=6378273 +units=m +no_defs \nsource      : AMSR_U2_L3_SeaIce12km_B04_20140314.he5://SI_12km_NH_ICECON_DAY \nvarname     : SI_12km_NH_ICECON_DAY \nname        : SI_12km_NH_ICECON_DAY\nWhy are the dimensions different?\ndim(r)\n\n[1] 897 608   1\n\ndim(ice_layer)\n\n[1] 896 608   1\nplot(ice_layer)",
    "crumbs": [
      "Importing",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>HE5 format</span>"
    ]
  },
  {
    "objectID": "chapters/importing/03_he5.html#using-terra-directly",
    "href": "chapters/importing/03_he5.html#using-terra-directly",
    "title": "3  HE5 format",
    "section": "",
    "text": "Warning\n\n\n\nReading data from HE5 files using the terra package may not always work correctly, and you might encounter the error message “cannot find the spatial extent.” If this happens, you can use the gdalraster package to read the data and then convert it to a SpatRaster object (as seen above).\nTo read data directly from an HE5 file with terra, ensure that terra is built with recent versions of the GDAL and PROJ libraries. Note that compatibility with GDAL v3.9.x is unlikely.",
    "crumbs": [
      "Importing",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>HE5 format</span>"
    ]
  },
  {
    "objectID": "chapters/importing/04_modis.html",
    "href": "chapters/importing/04_modis.html",
    "title": "4  HDF5 and NetCDF Files from MODIS Ocean Color Data",
    "section": "",
    "text": "4.1 L3BIN (Level-3 Binned Data) - HDF5\nIn these examples, we will use data from: Earth data. This website provides direct access to ocean color data products from various satellite missions, including MODIS. You can find Level-3 binned and mapped data here.\nLevel-3 binned (L3b) files are HDF5 files containing data that has been statistically processed and binned into spatial grids. The data is organized in layers, where each layer represents a different variable. These layers are stored in the /level-3_binned_data group within the HDF5 file. The BinList layer is particularly important, as it contains the bin information, such as the bin’s coordinates and the bin’s weights, which are crucial for proper interpretation of the data.\nIn R, these files can be read using the rhdf5 package from bioconductor. If you haven’t already, you’ll need to install the rhdf5 package. The following code shows how to install the package and then reads the chlor_a layer (chlorophyll-a concentration) from the file A2016160.L3b_DAY_CHL.nc:\nif (!require(\"BiocManager\", quietly = TRUE)) {\n  install.packages(\"BiocManager\")\n}\n\nBiocManager::install()\n\nBiocManager::install(\"rhdf5\")\nThe h5ls() function will list all the layers included in the HDF5 file. This is useful for exploring the file’s structure and identifying the available datasets.\nfile &lt;- here::here(\"data\", \"AQUA_MODIS.20160608.L3b.DAY.CHL.nc\")\nh5ls(file)\n\nDatatype: binDataType\nDatatype: binIndexType\nDatatype: binListType\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\ngroup\nname\notype\ndclass\ndim\n\n\n\n\n0\n/\nlevel-3_binned_data\nH5I_GROUP\n\n\n\n\n1\n/level-3_binned_data\nBinIndex\nH5I_DATASET\nCOMPOUND\n4320\n\n\n2\n/level-3_binned_data\nBinList\nH5I_DATASET\nCOMPOUND\n2417047\n\n\n3\n/level-3_binned_data\nbinDataDim\nH5I_DATASET\nFLOAT\n0\n\n\n4\n/level-3_binned_data\nbinIndexDim\nH5I_DATASET\nFLOAT\n0\n\n\n5\n/level-3_binned_data\nbinListDim\nH5I_DATASET\nFLOAT\n0\n\n\n6\n/level-3_binned_data\nchlor_a\nH5I_DATASET\nCOMPOUND\n2417047\n\n\n7\n/\nprocessing_control\nH5I_GROUP\n\n\n\n\n8\n/processing_control\ninput_parameters\nH5I_GROUP\nFinally, use h5read() to open a specific layer:\ndf &lt;- h5read(file, \"/level-3_binned_data/chlor_a\")\nhead(df)\n\n\n\n\n\nsum\nsum_squared\n\n\n\n\n0.1869691\n0.03495743\n\n\n0.2829849\n0.05712159\n\n\n0.4636284\n0.09679225\n\n\n0.6681932\n0.13557214\n\n\n0.5648066\n0.12085202\n\n\n0.4852219\n0.09646683\nThe resulting data frame df will contain the binned chlorophyll-a data. The columns in this data frame represent:\nTo apply the weights, read the BinList layer and divide the sum column by the weights column:\nbins &lt;- h5read(file, \"/level-3_binned_data/BinList\")\n\ndf[[\"sum\"]] &lt;- df[[\"sum\"]] / bins[[\"weights\"]]\n\nhead(df)\n\n\n\n\n\nsum\nsum_squared\n\n\n\n\n0.1869691\n0.03495743\n\n\n0.2001005\n0.05712159\n\n\n0.2073409\n0.09679225\n\n\n0.2014678\n0.13557214\n\n\n0.2134768\n0.12085202\n\n\n0.1980910\n0.09646683\nThe df[[\"sum\"]] column now contains the weighted average chlorophyll-a concentration for each bin. You can now perform further analysis or visualization with this data.",
    "crumbs": [
      "Importing",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>HDF5 and NetCDF Files from MODIS Ocean Color Data</span>"
    ]
  },
  {
    "objectID": "chapters/importing/04_modis.html#l3bin-level-3-binned-data---hdf5",
    "href": "chapters/importing/04_modis.html#l3bin-level-3-binned-data---hdf5",
    "title": "4  HDF5 and NetCDF Files from MODIS Ocean Color Data",
    "section": "",
    "text": "sum: The sum of the chlorophyll-a values of all pixels within the bin.\nsum_squared: The sum of the squared chlorophyll-a values within the bin. This can be used to calculate the variance or standard deviation of the data within the bin.\n\n\n\n\n\n\n\nImportant: Applying Weights\n\n\n\nIt is crucial to understand that the observed values in the sum column need to be weighted to obtain the actual average chlorophyll-a concentration for each bin. The weights, representing the relative contribution of each pixel to the bin, are stored in the BinList layer.",
    "crumbs": [
      "Importing",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>HDF5 and NetCDF Files from MODIS Ocean Color Data</span>"
    ]
  },
  {
    "objectID": "chapters/importing/04_modis.html#l3map-level-3-mapped-data---netcdf",
    "href": "chapters/importing/04_modis.html#l3map-level-3-mapped-data---netcdf",
    "title": "4  HDF5 and NetCDF Files from MODIS Ocean Color Data",
    "section": "4.2 L3MAP (Level-3 Mapped Data) - NetCDF",
    "text": "4.2 L3MAP (Level-3 Mapped Data) - NetCDF\nLevel-3 mapped (L3m) data represents geophysical variables projected onto a regular grid. These files are typically easier to visualize than L3b data because they are already in a gridded format.\n\nfile &lt;- here::here(\"data\", \"AQUA_MODIS.20160608.L3m.DAY.CHL.chlor_a.4km.nc\")\n\nr &lt;- rast(file)\n\nr\n\nclass       : SpatRaster \ndimensions  : 4320, 8640, 1  (nrow, ncol, nlyr)\nresolution  : 0.04166667, 0.04166667  (x, y)\nextent      : -180, 180, -90.00001, 90  (xmin, xmax, ymin, ymax)\ncoord. ref. : +proj=longlat +datum=WGS84 +no_defs \nsource      : AQUA_MODIS.20160608.L3m.DAY.CHL.chlor_a.4km.nc:chlor_a \nvarname     : chlor_a (Chlorophyll Concentration, OCI Algorithm) \nname        : chlor_a \nunit        : mg m^-3 \n\n\nThis shows the raster’s metadata, such as the number of layers, the number of rows and columns, the resolution, and the extent.\n\nwm &lt;- ne_countries(scale = \"medium\", returnclass = \"sf\")\n\nplot(wm[[\"geometry\"]], col = \"lightgray\", lwd = 0.5)\nplot(r, add = TRUE, col = terrain.colors(10L))",
    "crumbs": [
      "Importing",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>HDF5 and NetCDF Files from MODIS Ocean Color Data</span>"
    ]
  },
  {
    "objectID": "chapters/importing/04_modis.html#l3bin-level-3-binned-data---hdf4",
    "href": "chapters/importing/04_modis.html#l3bin-level-3-binned-data---hdf4",
    "title": "4  HDF5 and NetCDF Files from MODIS Ocean Color Data",
    "section": "4.3 L3BIN (Level-3 Binned Data) - hdf4",
    "text": "4.3 L3BIN (Level-3 Binned Data) - hdf4\n\nfilename &lt;- here::here(\"data\", \"MYD08_D3.A2003181.061.2018007232726.hdf\")\n\nsdss &lt;- describe(filename, sds = TRUE, meta = FALSE, parse = FALSE)\nhead(sdss)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nid\nname\nvar\ndesc\nnrow\nncol\nnlyr\n\n\n\n\n1\nHDF4_EOS:EOS_GRID:“/media/LaCie16TB/work/projects/documentation/read_rs_product/data/MYD08_D3.A2003181.061.2018007232726.hdf”:mod08:Solar_Zenith_Mean\nSolar_Zenith_Mean\n[180x360] Solar_Zenith_Mean mod08 (16-bit integer)\n180\n360\n1\n\n\n2\nHDF4_EOS:EOS_GRID:“/media/LaCie16TB/work/projects/documentation/read_rs_product/data/MYD08_D3.A2003181.061.2018007232726.hdf”:mod08:Solar_Zenith_Standard_Deviation\nSolar_Zenith_Standard_Deviation\n[180x360] Solar_Zenith_Standard_Deviation mod08 (16-bit integer)\n180\n360\n1\n\n\n3\nHDF4_EOS:EOS_GRID:“/media/LaCie16TB/work/projects/documentation/read_rs_product/data/MYD08_D3.A2003181.061.2018007232726.hdf”:mod08:Solar_Zenith_Minimum\nSolar_Zenith_Minimum\n[180x360] Solar_Zenith_Minimum mod08 (16-bit integer)\n180\n360\n1\n\n\n4\nHDF4_EOS:EOS_GRID:“/media/LaCie16TB/work/projects/documentation/read_rs_product/data/MYD08_D3.A2003181.061.2018007232726.hdf”:mod08:Solar_Zenith_Maximum\nSolar_Zenith_Maximum\n[180x360] Solar_Zenith_Maximum mod08 (16-bit integer)\n180\n360\n1\n\n\n5\nHDF4_EOS:EOS_GRID:“/media/LaCie16TB/work/projects/documentation/read_rs_product/data/MYD08_D3.A2003181.061.2018007232726.hdf”:mod08:Solar_Zenith_Pixel_Counts\nSolar_Zenith_Pixel_Counts\n[180x360] Solar_Zenith_Pixel_Counts mod08 (16-bit integer)\n180\n360\n1\n\n\n6\nHDF4_EOS:EOS_GRID:“/media/LaCie16TB/work/projects/documentation/read_rs_product/data/MYD08_D3.A2003181.061.2018007232726.hdf”:mod08:Solar_Azimuth_Mean\nSolar_Azimuth_Mean\n[180x360] Solar_Azimuth_Mean mod08 (16-bit integer)\n180\n360\n1\n\n\n\n\n\nr &lt;- rast(filename, 142L)\n\nplot(r)",
    "crumbs": [
      "Importing",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>HDF5 and NetCDF Files from MODIS Ocean Color Data</span>"
    ]
  },
  {
    "objectID": "chapters/importing/05_vsicurl.html",
    "href": "chapters/importing/05_vsicurl.html",
    "title": "5  GDAL Virtual File Systems",
    "section": "",
    "text": "5.1 Reading the data from a GeoTIFF file\nr &lt;- terra::rast(\n  \"/vsicurl/https://gebco2023.s3.valeria.science/gebco_2023_sub_ice_topo_cog.tif\"\n)\n\nr\n\nclass       : SpatRaster \ndimensions  : 43200, 86400, 1  (nrow, ncol, nlyr)\nresolution  : 0.004166667, 0.004166667  (x, y)\nextent      : -180, 180, -90, 90  (xmin, xmax, ymin, ymax)\ncoord. ref. : lon/lat WGS 84 (EPSG:4326) \nsource      : gebco_2023_sub_ice_topo_cog.tif \nname        : gebco_2023_sub_ice_topo_cog \n\nplot(r)",
    "crumbs": [
      "Importing",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>GDAL Virtual File Systems</span>"
    ]
  },
  {
    "objectID": "chapters/importing/05_vsicurl.html#reading-the-data-from-a-geotiff-file",
    "href": "chapters/importing/05_vsicurl.html#reading-the-data-from-a-geotiff-file",
    "title": "5  GDAL Virtual File Systems",
    "section": "",
    "text": "vsicurl: https://gdal.org/drivers/raster/vsicurl.html is a GDAL virtual file system that allows reading files from a URL.",
    "crumbs": [
      "Importing",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>GDAL Virtual File Systems</span>"
    ]
  },
  {
    "objectID": "chapters/importing/05_vsicurl.html#vsigzip",
    "href": "chapters/importing/05_vsicurl.html#vsigzip",
    "title": "5  GDAL Virtual File Systems",
    "section": "5.2 vsigzip",
    "text": "5.2 vsigzip\n\nvsigzip: https://gdal.org/drivers/raster/vsigzip.html is a GDAL virtual file system that allows reading files from a gzip compressed file.\n\n\nsic &lt;- rast(\n  \"/vsigzip//vsicurl/ftp://ftp-projects.cen.uni-hamburg.de/seaice/AMSR2/3.125km/Arc_20201010_res3.125_pyres.nc.gz\",\n  \"sea_ice_concentration\"\n)\n\nsic\n\nclass       : SpatRaster \ndimensions  : 3584, 2432, 1  (nrow, ncol, nlyr)\nresolution  : 1, 1  (x, y)\nextent      : 0.5, 2432.5, 0.5, 3584.5  (xmin, xmax, ymin, ymax)\ncoord. ref. : +proj=longlat +datum=WGS84 +no_defs \nsource      : Arc_20201010_res3.125_pyres.nc.gz:sea_ice_concentration \nvarname     : sea_ice_concentration (daily averaged total ice concentration) \nname        : sea_ice_concentration \nunit        :                     % \ntime        : 2020-10-10 12:00:00 UTC \n\nplot(sic)\n\n\n\n\n\n\n\n\nFrom the documentation, we expect that data to be in polar stereographic projection with a specific extent. However, the data does not have the correct extent and projection. We can set the extent and projection manually:\n\n# Set the extent\next(sic) &lt;- ext(-3850000L, 3750000L, -5350000L, 5850000L)\n\n# Set the polar stereographic projection\ncrs(sic) &lt;- \"EPSG:3413\"\n\nsic\n\nclass       : SpatRaster \ndimensions  : 3584, 2432, 1  (nrow, ncol, nlyr)\nresolution  : 3125, 3125  (x, y)\nextent      : -3850000, 3750000, -5350000, 5850000  (xmin, xmax, ymin, ymax)\ncoord. ref. : WGS 84 / NSIDC Sea Ice Polar Stereographic North (EPSG:3413) \nsource      : Arc_20201010_res3.125_pyres.nc.gz:sea_ice_concentration \nvarname     : sea_ice_concentration (daily averaged total ice concentration) \nname        : sea_ice_concentration \nunit        :                     % \ntime        : 2020-10-10 12:00:00 UTC \n\n\nNow the data has the correct extent and projection. Each pixel represents the sea ice concentration in a 3.125 km x 3.125 km area.\n\nplot(sic)",
    "crumbs": [
      "Importing",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>GDAL Virtual File Systems</span>"
    ]
  },
  {
    "objectID": "chapters/filtering/01_filtering.html",
    "href": "chapters/filtering/01_filtering.html",
    "title": "6  Filtering spatial data",
    "section": "",
    "text": "6.1 Filtering spatial data with sf\nIn this tutorial, we will explore different methods to filter spatial data using the sf package in R. We will use the Canadian Wind Turbine Database as our example dataset.\nThe Canadian Wind Turbine Database contains the geographic location and key technology details for wind turbines installed in Canada.\n# URL to the wind turbine database\nurl &lt;- \"/vsizip//vsicurl/https://ftp.cartes.canada.ca/pub/nrcan_rncan/Wind-energy_Energie-eolienne/wind_turbines_database/wind_turbine_database_en.gdb.zip\"\n\n# List layers in the dataset\nst_layers(url)\n\n\n\n\n\n\n\n\n\n\n\n\n\nname\ngeomtype\ndriver\nfeatures\nfields\ncrs\n\n\n\n\nwind_turbine\nPoint\nOpenFileGDB\n7578\n17\nNAD83 / Canada Atlas Lambert , PROJCRS[“NAD83 / Canada Atlas Lambert”,\n\n\n\nBASEGEOGCRS[\"NAD83\",\n    DATUM[\"North American Datum 1983\",\n        ELLIPSOID[\"GRS 1980\",6378137,298.257222101,\n            LENGTHUNIT[\"metre\",1]]],\n    PRIMEM[\"Greenwich\",0,\n        ANGLEUNIT[\"degree\",0.0174532925199433]],\n    ID[\"EPSG\",4269]],\nCONVERSION[\"Canada Atlas Lambert\",\n    METHOD[\"Lambert Conic Conformal (2SP)\",\n        ID[\"EPSG\",9802]],\n    PARAMETER[\"Latitude of false origin\",49,\n        ANGLEUNIT[\"degree\",0.0174532925199433],\n        ID[\"EPSG\",8821]],\n    PARAMETER[\"Longitude of false origin\",-95,\n        ANGLEUNIT[\"degree\",0.0174532925199433],\n        ID[\"EPSG\",8822]],\n    PARAMETER[\"Latitude of 1st standard parallel\",49,\n        ANGLEUNIT[\"degree\",0.0174532925199433],\n        ID[\"EPSG\",8823]],\n    PARAMETER[\"Latitude of 2nd standard parallel\",77,\n        ANGLEUNIT[\"degree\",0.0174532925199433],\n        ID[\"EPSG\",8824]],\n    PARAMETER[\"Easting at false origin\",0,\n        LENGTHUNIT[\"metre\",1],\n        ID[\"EPSG\",8826]],\n    PARAMETER[\"Northing at false origin\",0,\n        LENGTHUNIT[\"metre\",1],\n        ID[\"EPSG\",8827]]],\nCS[Cartesian,2],\n    AXIS[\"(E)\",east,\n        ORDER[1],\n        LENGTHUNIT[\"metre\",1]],\n    AXIS[\"(N)\",north,\n        ORDER[2],\n        LENGTHUNIT[\"metre\",1]],\nUSAGE[\n    SCOPE[\"Transformation of coordinates at 5m level of accuracy.\"],\n    AREA[\"Canada - onshore and offshore - Alberta; British Columbia; Manitoba; New Brunswick; Newfoundland and Labrador; Northwest Territories; Nova Scotia; Nunavut; Ontario; Prince Edward Island; Quebec; Saskatchewan; Yukon.\"],\n    BBOX[38.21,-141.01,86.46,-40.73]],\nID[\"EPSG\",3978]] |\n\n\n# Read the entire dataset\npts &lt;- read_sf(url)\n\n# Load and transform Canada map\ncanada &lt;- ne_countries(\n  scale = \"medium\",\n  returnclass = \"sf\",\n  country = \"Canada\"\n) |&gt;\n  st_transform(crs = \"EPSG:3978\")\n\n# Plot the map with wind turbine points\nggplot() +\n  geom_sf(data = canada) +\n  geom_sf(data = pts, color = \"red\", size = 0.5)",
    "crumbs": [
      "Filtering",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Filtering spatial data</span>"
    ]
  },
  {
    "objectID": "chapters/filtering/01_filtering.html#filtering-spatial-data-with-a-bounding-box",
    "href": "chapters/filtering/01_filtering.html#filtering-spatial-data-with-a-bounding-box",
    "title": "6  Filtering spatial data",
    "section": "6.2 Filtering spatial data with a bounding box",
    "text": "6.2 Filtering spatial data with a bounding box\nTo avoid loading the entire dataset into memory, we can filter the data using a bounding box. This is particularly useful when working with large datasets. We can leverage the wkt_filter argument to filter spatial data and reduce the amount of data loaded into memory.\n\n# Read and transform the area of interest\narea &lt;- read_sf(here::here(\"data\", \"area.geojson\")) |&gt;\n  st_transform(crs = st_crs(pts))\n\n# Plot the map with the area of interest\nggplot() +\n  geom_sf(data = canada) +\n  geom_sf(data = area, color = \"blue\", fill = NA, linewidth = 1L) +\n  geom_sf(data = pts, color = \"red\", size = 0.5)\n\n\n\n\n\n\n\n\nInstead of loading the entire dataset into memory, we can filter the data using a bounding box.\n\n# Convert the area geometry to WKT\nwkt &lt;- area |&gt;\n  st_geometry() |&gt;\n  st_as_text()\n\n# Read the filtered dataset using the bounding box\nfiltered &lt;- read_sf(url, wkt_filter = wkt)\nfiltered[[\"Notes\"]] &lt;- NULL\n\n\n# Plot the filtered data\nggplot() +\n  geom_sf(data = canada) +\n  geom_sf(data = area, color = \"blue\", fill = NA, linewidth = 1L) +\n  geom_sf(data = filtered, color = \"red\", size = 0.5)\n\n\n\n\n\n\n\n# Display the number of rows and the first few rows of the filtered data\nnrow(filtered)\n\n[1] 2032\n\nhead(filtered)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nProvince_Territory\nProject_Name\nTotal_Project_Capacity_MW\nTurbine_Identifier\nTurbine_Number\nTurbine_Number_in_Project\nTurbine_Rated_Capacity_kW\nRotor_Diameter_m\nHub_Height_m\nManufacturer\nModel\nCommissioning\nLatitude\nLongitude\nData_Sources\nBasemap\nShape\n\n\n\n\nNew Brunswick\nBurchill\n42\nBRH1\n1\n1/10\n4200\n141\n135\nEnercon\nE141-4.2\n2023\n45.15949\n-66.19081\n[70], [71], [910]\nESRI\nPOINT (2225020 82296.21)\n\n\nNew Brunswick\nBurchill\n42\nBRH2\n2\n2/10\n4200\n141\n135\nEnercon\nE141-4.2\n2023\n45.16434\n-66.19718\n[70], [71], [910]\nESRI\nPOINT (2224322 82566.09)\n\n\nNew Brunswick\nBurchill\n42\nBRH3\n3\n3/10\n4200\n141\n135\nEnercon\nE141-4.2\n2023\n45.16875\n-66.20070\n[70], [71], [910]\nESRI\nPOINT (2223851 82890.97)\n\n\nNew Brunswick\nBurchill\n42\nBRH4\n4\n4/10\n4200\n141\n135\nEnercon\nE141-4.2\n2023\n45.17307\n-66.20036\n[70], [71], [910]\nESRI\nPOINT (2223662 83342.02)\n\n\nNew Brunswick\nBurchill\n42\nBRH5\n5\n5/10\n4200\n141\n135\nEnercon\nE141-4.2\n2023\n45.17834\n-66.19340\n[70], [71], [910]\nESRI\nPOINT (2223902 84120.34)\n\n\nNew Brunswick\nBurchill\n42\nBRH6\n6\n6/10\n4200\n141\n135\nEnercon\nE141-4.2\n2023\n45.18281\n-66.18900\n[70], [71], [910]\nESRI\nPOINT (2223997 84728.45)",
    "crumbs": [
      "Filtering",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Filtering spatial data</span>"
    ]
  },
  {
    "objectID": "chapters/filtering/01_filtering.html#refining-the-filter-with-a-user-defined-sql-query",
    "href": "chapters/filtering/01_filtering.html#refining-the-filter-with-a-user-defined-sql-query",
    "title": "6  Filtering spatial data",
    "section": "6.3 Refining the filter with a user-defined SQL query",
    "text": "6.3 Refining the filter with a user-defined SQL query\nWe can further refine our filter by using a user-defined query. For example, we can filter the wind turbines based on their rated capacity.\n\n# Display the range of turbine capacities\nrange(filtered[[\"Turbine_Rated_Capacity__kW_\"]])\n\n[1]    0 4200\n\n\nTo refine the filter, we can use a custom query to select only the wind turbines with a rated capacity greater than 4000 kW. First, we need to identify the layer name to use in the SQL query.\n\n# List layers in the dataset\nst_layers(url)\n\n\n\n\n\n\n\n\n\n\n\n\n\nname\ngeomtype\ndriver\nfeatures\nfields\ncrs\n\n\n\n\nwind_turbine\nPoint\nOpenFileGDB\n7578\n17\nNAD83 / Canada Atlas Lambert , PROJCRS[“NAD83 / Canada Atlas Lambert”,\n\n\n\nBASEGEOGCRS[\"NAD83\",\n    DATUM[\"North American Datum 1983\",\n        ELLIPSOID[\"GRS 1980\",6378137,298.257222101,\n            LENGTHUNIT[\"metre\",1]]],\n    PRIMEM[\"Greenwich\",0,\n        ANGLEUNIT[\"degree\",0.0174532925199433]],\n    ID[\"EPSG\",4269]],\nCONVERSION[\"Canada Atlas Lambert\",\n    METHOD[\"Lambert Conic Conformal (2SP)\",\n        ID[\"EPSG\",9802]],\n    PARAMETER[\"Latitude of false origin\",49,\n        ANGLEUNIT[\"degree\",0.0174532925199433],\n        ID[\"EPSG\",8821]],\n    PARAMETER[\"Longitude of false origin\",-95,\n        ANGLEUNIT[\"degree\",0.0174532925199433],\n        ID[\"EPSG\",8822]],\n    PARAMETER[\"Latitude of 1st standard parallel\",49,\n        ANGLEUNIT[\"degree\",0.0174532925199433],\n        ID[\"EPSG\",8823]],\n    PARAMETER[\"Latitude of 2nd standard parallel\",77,\n        ANGLEUNIT[\"degree\",0.0174532925199433],\n        ID[\"EPSG\",8824]],\n    PARAMETER[\"Easting at false origin\",0,\n        LENGTHUNIT[\"metre\",1],\n        ID[\"EPSG\",8826]],\n    PARAMETER[\"Northing at false origin\",0,\n        LENGTHUNIT[\"metre\",1],\n        ID[\"EPSG\",8827]]],\nCS[Cartesian,2],\n    AXIS[\"(E)\",east,\n        ORDER[1],\n        LENGTHUNIT[\"metre\",1]],\n    AXIS[\"(N)\",north,\n        ORDER[2],\n        LENGTHUNIT[\"metre\",1]],\nUSAGE[\n    SCOPE[\"Transformation of coordinates at 5m level of accuracy.\"],\n    AREA[\"Canada - onshore and offshore - Alberta; British Columbia; Manitoba; New Brunswick; Newfoundland and Labrador; Northwest Territories; Nova Scotia; Nunavut; Ontario; Prince Edward Island; Quebec; Saskatchewan; Yukon.\"],\n    BBOX[38.21,-141.01,86.46,-40.73]],\nID[\"EPSG\",3978]] |\n\n\n\nWe can use wind_turbine as the layer name in the custom query.\n\n# Read the filtered dataset with a custom query\nhigh_capacity &lt;- read_sf(\n  url,\n  wkt_filter = wkt,\n  query = \"SELECT * FROM wind_turbine WHERE Turbine_Rated_Capacity__kW_ &gt; 4000\"\n)\n\nhigh_capacity[[\"Notes\"]] &lt;- NULL\n\n# Display the number of rows and the first few rows of the high capacity data\nnrow(high_capacity)\n\n[1] 10\n\n# Plot the high capacity turbines\nggplot() +\n  geom_sf(data = canada) +\n  geom_sf(data = area, color = \"blue\", fill = NA, linewidth = 1L) +\n  geom_sf(data = high_capacity, color = \"red\", size = 0.5)",
    "crumbs": [
      "Filtering",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Filtering spatial data</span>"
    ]
  },
  {
    "objectID": "chapters/filtering/01_filtering.html#filtering-spatial-data-with-duckdb",
    "href": "chapters/filtering/01_filtering.html#filtering-spatial-data-with-duckdb",
    "title": "6  Filtering spatial data",
    "section": "6.4 Filtering spatial data with DuckDB",
    "text": "6.4 Filtering spatial data with DuckDB\nIn this section, we will demonstrate how to filter spatial data using DuckDB. DuckDB is an embedded analytical database that supports spatial extensions.\n\n# Connect to DuckDB\nconn &lt;- dbConnect(duckdb())\n\n# Install and load the spatial extension\ndbSendQuery(conn, \"INSTALL spatial;\")\ndbSendQuery(conn, \"LOAD spatial;\")\n\n# Create a table with spatial data filtered by a bounding box\ndbSendQuery(\n  conn,\n  \"\n  CREATE\n  OR REPLACE TABLE t AS\n  SELECT\n   *,\n   ST_asWKB(geom) AS geometry\n  FROM\n   ST_Read('/vsis3/spatial-playground/gmw_v3.fgb', spatial_filter_box = {'min_x' : - 30, 'min_y' : 0, 'max_x' : - 50, 'max_y' : 45});\n  \"\n)\n\n# Read the filtered data from DuckDB\nread_sf(conn, query = \"SELECT * FROM t\", geometry_column = \"geometry\")\n\n# Read the filtered data with an additional computed area column\nread_sf(\n  conn,\n  query = \"SELECT *, ST_Area(geom) as area1 FROM t\",\n  geometry_column = \"geometry\"\n) |&gt;\n  mutate(area2 = st_area(geometry), .after = area1)",
    "crumbs": [
      "Filtering",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Filtering spatial data</span>"
    ]
  },
  {
    "objectID": "chapters/plotting/01_basics.html",
    "href": "chapters/plotting/01_basics.html",
    "title": "7  Plotting spatial data",
    "section": "",
    "text": "library(terra)\nlibrary(ggplot2)\nlibrary(tidyterra)\n\n\nfile &lt;- here::here(\"data\", \"avhrr-only-v2.20160503.nc\")\n\n\nsst_layer &lt;- rast(file, subds = \"sst\") |&gt;\n  rotate()\n\nsst_layer\n\nclass       : SpatRaster \ndimensions  : 720, 1440, 1  (nrow, ncol, nlyr)\nresolution  : 0.25, 0.25  (x, y)\nextent      : -180, 180, -90, 90  (xmin, xmax, ymin, ymax)\ncoord. ref. : lon/lat WGS 84 (CRS84) (OGC:CRS84) \nsource(s)   : memory\nvarname     : sst (Daily sea surface temperature) \nname        : sst_zlev=0 \nmin value   :      -1.80 \nmax value   :      32.69 \nunit        :  degrees C \ntime (days) : 2016-05-03 \n\n\n\nplot(sst_layer)\n\n\n\n\n\n\n\n\n\nggplot() +\n  geom_spatraster(data = sst_layer) +\n  scale_fill_viridis_c(na.value = \"transparent\") +\n  labs(fill = \"Sea Surface\\nTemperature (°C)\") +\n  coord_sf(crs = \"+proj=robin\")",
    "crumbs": [
      "Plotting",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Plotting spatial data</span>"
    ]
  },
  {
    "objectID": "chapters/manipulating/01_spatial_resolution.html",
    "href": "chapters/manipulating/01_spatial_resolution.html",
    "title": "8  Spatial resolution",
    "section": "",
    "text": "library(terra)\nlibrary(tidyterra)\n\n\nRead the Baffin Bay polygon.\nRead bathymetry data from the GEBCO 2022 dataset and crop it to the Baffin Bay extent using the win argument.\n\n\nbaffin &lt;- vect(\"https://github.com/PMassicotte/baffin_bay_polygon/blob/main/data/clean/baffin_bay.gpkg?raw=true\")\n\n\ncrop_extent &lt;- ext(project(baffin, \"EPSG:4326\"))\n\nwm &lt;- rnaturalearth::ne_countries(scale = \"medium\", returnclass = \"sv\")\n\nplot(wm, lwd = 0.25)\nplot(project(baffin, \"EPSG:4326\"), add = TRUE, col = \"red\")\n\n\n\n\n\n\n\n\n\nr &lt;- rast(\n  \"/vsicurl/https://gebco2022.s3.valeria.science/gebco_2022_complete_cog.tif\",\n  win = crop_extent\n) |&gt;\n  project(crs(baffin))\n\nplot(r)\n\n\n\n\n\n\n\n\n\nSet a new resolution at 50 km\nResample the raster using the bilinear method\nPlot the original and resampled rasters\nCompare the original and resampled resolution\n\n\nr2 &lt;- rast(ext(r))\nr2\n\nclass       : SpatRaster \ndimensions  : 10, 10, 1  (nrow, ncol, nlyr)\nresolution  : 163627.1, 186358.9  (x, y)\nextent      : 40471768, 42108039, 4602532, 6466121  (xmin, xmax, ymin, ymax)\ncoord. ref. :  \n\nres(r2) &lt;- 50000L\n\nr2 &lt;- resample(r, r2, method = \"bilinear\")\n\nop &lt;- par(mfrow = c(1L, 2L))\nplot(r)\nplot(r2)\n\n\n\n\n\n\n\npar(op)\n\nplot(as.polygons(r2))\nplot(as.points(r2), cex = 0.2, add = TRUE, col = \"red\")\n\n\n\n\n\n\n\nplot(r2)\nplot(as.lines(r2), add = TRUE)\n\n\n\n\n\n\n\nr\n\nclass       : SpatRaster \ndimensions  : 8067, 7083, 1  (nrow, ncol, nlyr)\nresolution  : 231.0138, 231.0138  (x, y)\nextent      : 40471768, 42108039, 4602532, 6466121  (xmin, xmax, ymin, ymax)\ncoord. ref. : GR96 / EPSG Arctic zone 5-41 (EPSG:6059) \nsource(s)   : memory\nname        : gebco_2022_complete_cog \nmin value   :               -2426.086 \nmax value   :                2273.907 \n\nr2\n\nclass       : SpatRaster \ndimensions  : 37, 33, 1  (nrow, ncol, nlyr)\nresolution  : 50000, 50000  (x, y)\nextent      : 40471768, 42121768, 4602532, 6452532  (xmin, xmax, ymin, ymax)\ncoord. ref. : GR96 / EPSG Arctic zone 5-41 (EPSG:6059) \nsource(s)   : memory\nname        : gebco_2022_complete_cog \nmin value   :               -2348.460 \nmax value   :                1251.003 \n\n\n\nr3 &lt;- mask(r2, baffin, touches = FALSE)\nplot(r3)\nplot(baffin, add = TRUE)",
    "crumbs": [
      "Manipulating",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Spatial resolution</span>"
    ]
  },
  {
    "objectID": "chapters/manipulating/02_database.html",
    "href": "chapters/manipulating/02_database.html",
    "title": "9  Spatial databases",
    "section": "",
    "text": "9.1 Create a connection to DuckDB\nlibrary(DBI)\nlibrary(duckdb)\nlibrary(sf)\nlibrary(dplyr)\n\nconn &lt;- dbConnect(duckdb())",
    "crumbs": [
      "Manipulating",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Spatial databases</span>"
    ]
  },
  {
    "objectID": "chapters/manipulating/02_database.html#file-path-and-database-setup",
    "href": "chapters/manipulating/02_database.html#file-path-and-database-setup",
    "title": "9  Spatial databases",
    "section": "9.2 File Path and Database Setup",
    "text": "9.2 File Path and Database Setup\nHere, the code retrieves the file path of a sample GeoPackage file included with the sf package. It also installs and loads the necessary extensions (httpfs and spatial) in DuckDB to handle spatial data.\n\nfile &lt;- system.file(\"gpkg/nc.gpkg\", package = \"sf\")\n\ndbExecute(conn, \"INSTALL httpfs; LOAD httpfs; INSTALL spatial; LOAD spatial\")\n\n[1] 0",
    "crumbs": [
      "Manipulating",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Spatial databases</span>"
    ]
  },
  {
    "objectID": "chapters/manipulating/02_database.html#creating-a-table-with-spatial-data",
    "href": "chapters/manipulating/02_database.html#creating-a-table-with-spatial-data",
    "title": "9  Spatial databases",
    "section": "9.3 Creating a Table with Spatial Data",
    "text": "9.3 Creating a Table with Spatial Data\nThis section constructs a SQL query to create a table (mytable) from the GeoPackage file. It reads the spatial data and converts the geometry column to Well-Known Binary (WKB) format. The query is then executed with the file path bound as a parameter.\n\nquery &lt;-\n  \"\n    CREATE OR REPLACE TABLE mytable AS\n    SELECT\n      *,\n      ST_asWKB (geom) AS geom2\n    FROM\n     ST_Read (?)\n  \"\n\nstmt &lt;- dbSendStatement(conn, query, params = list(file))\ndbGetRowsAffected(stmt)\n\n[1] 100\n\ndbClearResult(stmt)",
    "crumbs": [
      "Manipulating",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Spatial databases</span>"
    ]
  },
  {
    "objectID": "chapters/manipulating/02_database.html#describing-the-table",
    "href": "chapters/manipulating/02_database.html#describing-the-table",
    "title": "9  Spatial databases",
    "section": "9.4 Describing the Table",
    "text": "9.4 Describing the Table\nThis part describes the structure of the newly created table and lists all tables in the database.\n\ndbSendQuery(conn, \"DESCRIBE mytable;\") |&gt;\n  dbFetch()\n\n\n\n\n\ncolumn_name\ncolumn_type\nnull\nkey\ndefault\nextra\n\n\n\n\nAREA\nDOUBLE\nYES\nNA\nNA\nNA\n\n\nPERIMETER\nDOUBLE\nYES\nNA\nNA\nNA\n\n\nCNTY_\nDOUBLE\nYES\nNA\nNA\nNA\n\n\nCNTY_ID\nDOUBLE\nYES\nNA\nNA\nNA\n\n\nNAME\nVARCHAR\nYES\nNA\nNA\nNA\n\n\nFIPS\nVARCHAR\nYES\nNA\nNA\nNA\n\n\nFIPSNO\nDOUBLE\nYES\nNA\nNA\nNA\n\n\nCRESS_ID\nINTEGER\nYES\nNA\nNA\nNA\n\n\nBIR74\nDOUBLE\nYES\nNA\nNA\nNA\n\n\nSID74\nDOUBLE\nYES\nNA\nNA\nNA\n\n\nNWBIR74\nDOUBLE\nYES\nNA\nNA\nNA\n\n\nBIR79\nDOUBLE\nYES\nNA\nNA\nNA\n\n\nSID79\nDOUBLE\nYES\nNA\nNA\nNA\n\n\nNWBIR79\nDOUBLE\nYES\nNA\nNA\nNA\n\n\ngeom\nGEOMETRY\nYES\nNA\nNA\nNA\n\n\ngeom2\nWKB_BLOB\nYES\nNA\nNA\nNA\n\n\n\n\n\n\n\ndbSendQuery(\n  conn,\n  \"FROM (SUMMARIZE mytable) AS summarized_table WHERE NOT regexp_matches(column_name,'geom')\"\n) |&gt;\n  dbFetch()\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\ncolumn_name\ncolumn_type\nmin\nmax\napprox_unique\navg\nstd\nq25\nq50\nq75\ncount\nnull_percentage\n\n\n\n\nAREA\nDOUBLE\n0.042\n0.241\n86\n0.12626000000000004\n0.04920019298639987\n0.091\n0.1205\n0.1545\n100\n0\n\n\nPERIMETER\nDOUBLE\n0.999\n3.64\n92\n1.6729600000000004\n0.4823126510193709\n1.323\n1.6085\n1.863\n100\n0\n\n\nCNTY_\nDOUBLE\n1825.0\n2241.0\n112\n1985.96\n106.51664829328959\n1901.5\n1982.0\n2067.5\n100\n0\n\n\nCNTY_ID\nDOUBLE\n1825.0\n2241.0\n112\n1985.96\n106.51664829328959\n1901.5\n1982.0\n2067.5\n100\n0\n\n\nNAME\nVARCHAR\nAlamance\nYancey\n105\nNA\nNA\nNA\nNA\nNA\n100\n0\n\n\nFIPS\nVARCHAR\n37001\n37199\n83\nNA\nNA\nNA\nNA\nNA\n100\n0\n\n\nFIPSNO\nDOUBLE\n37001.0\n37199.0\n100\n37100.0\n58.022983951764346\n37050.0\n37100.0\n37150.0\n100\n0\n\n\nCRESS_ID\nINTEGER\n1\n100\n96\n50.5\n29.011491975882013\n26\n50\n76\n100\n0\n\n\nBIR74\nDOUBLE\n248.0\n21588.0\n101\n3299.62\n3848.1651269196336\n1063.0\n2180.5\n3957.0\n100\n0\n\n\nSID74\nDOUBLE\n0.0\n44.0\n24\n6.67\n7.781167371067509\n2.0\n4.0\n8.5\n100\n0\n\n\nNWBIR74\nDOUBLE\n1.0\n8027.0\n96\n1050.81\n1432.9117399353129\n180.0\n697.5\n1172.0\n100\n0\n\n\nBIR79\nDOUBLE\n319.0\n30757.0\n98\n4223.92\n5179.458159095233\n1308.5\n2636.0\n4989.0\n100\n0\n\n\nSID79\nDOUBLE\n0.0\n57.0\n29\n8.36\n9.431860898041274\n2.0\n5.0\n10.5\n100\n0\n\n\nNWBIR79\nDOUBLE\n3.0\n11631.0\n101\n1352.81\n1975.9987511497711\n241.0\n874.5\n1416.5\n100\n0",
    "crumbs": [
      "Manipulating",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Spatial databases</span>"
    ]
  },
  {
    "objectID": "chapters/manipulating/02_database.html#reading-and-converting-spatial-data",
    "href": "chapters/manipulating/02_database.html#reading-and-converting-spatial-data",
    "title": "9  Spatial databases",
    "section": "9.5 Reading and Converting Spatial Data",
    "text": "9.5 Reading and Converting Spatial Data\nHere, the code reads the spatial data from the mytable table, specifying the geometry column (geom2). The result is converted to a tibble and then to an sf object for spatial data manipulation.\n\nres &lt;- st_read(\n  conn,\n  query =\n    \"\n      SELECT\n        *\n      FROM\n       mytable;\n    \",\n  geometry_column = \"geom2\"\n) |&gt;\n  st_as_sf() |&gt;\n  select(-geom) |&gt;\n  head()",
    "crumbs": [
      "Manipulating",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Spatial databases</span>"
    ]
  },
  {
    "objectID": "chapters/manipulating/02_database.html#filtering-and-plotting-spatial-data",
    "href": "chapters/manipulating/02_database.html#filtering-and-plotting-spatial-data",
    "title": "9  Spatial databases",
    "section": "9.6 Filtering and Plotting Spatial Data",
    "text": "9.6 Filtering and Plotting Spatial Data\nFilter the spatial data based on intersection with a specific point.\n\ntbl(conn, \"mytable\") |&gt;\n  filter(ST_Intersects(geom, \"SRID=4326;POINT (-81.5 36.43)\")) |&gt;\n  select(-contains(\"geom\"))\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nAREA\nPERIMETER\nCNTY_\nCNTY_ID\nNAME\nFIPS\nFIPSNO\nCRESS_ID\nBIR74\nSID74\nNWBIR74\nBIR79\nSID79\nNWBIR79\n\n\n\n\n0.114\n1.442\n1825\n1825\nAshe\n37009\n37009\n5\n1091\n1\n10\n1364\n0\n19",
    "crumbs": [
      "Manipulating",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Spatial databases</span>"
    ]
  },
  {
    "objectID": "chapters/manipulating/02_database.html#filter-by-area-and-plot",
    "href": "chapters/manipulating/02_database.html#filter-by-area-and-plot",
    "title": "9  Spatial databases",
    "section": "9.7 Filter by Area and Plot",
    "text": "9.7 Filter by Area and Plot\nFilter the spatial data based on area greater than 0.14 and plot the results.\n\nres &lt;- tbl(conn, \"mytable\") |&gt;\n  filter(ST_Area(geom) &gt; 0.14) |&gt;\n  collect() |&gt;\n  st_as_sf()\n\nwkbType: 67108864\n\nplot(st_geometry(res), lwd = 0.5)",
    "crumbs": [
      "Manipulating",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Spatial databases</span>"
    ]
  },
  {
    "objectID": "chapters/references.html",
    "href": "chapters/references.html",
    "title": "Additional Resources",
    "section": "",
    "text": "Useful Links",
    "crumbs": [
      "Additional Resources"
    ]
  },
  {
    "objectID": "chapters/references.html#useful-links",
    "href": "chapters/references.html#useful-links",
    "title": "Additional Resources",
    "section": "",
    "text": "HDF EOS Tools and Information Center\nAMSR-E/AMSR2 Unified L3 Daily 12.5 km Brightness Temperatures, Sea Ice Concentration, Motion & Snow Depth Polar Grids, Version 1",
    "crumbs": [
      "Additional Resources"
    ]
  },
  {
    "objectID": "chapters/references.html#session-info",
    "href": "chapters/references.html#session-info",
    "title": "Additional Resources",
    "section": "Session Info",
    "text": "Session Info\n\n\nsessioninfo::session_info()\n\n─ Session info ───────────────────────────────────────────────────────────────\n setting  value\n version  R version 4.4.2 (2024-10-31)\n os       Linux Mint 22\n system   x86_64, linux-gnu\n ui       X11\n language en_CA:en\n collate  en_CA.UTF-8\n ctype    en_CA.UTF-8\n tz       America/Montreal\n date     2025-02-11\n pandoc   3.1.3 @ /usr/bin/ (via rmarkdown)\n quarto   1.6.39 @ /usr/local/bin/quarto\n\n─ Packages ───────────────────────────────────────────────────────────────────\n ! package     * version date (UTC) lib source\n P BiocManager   1.30.25 2024-08-28 [?] RSPM\n P cli           3.6.3   2024-06-21 [?] CRAN (R 4.4.1)\n P digest        0.6.37  2024-08-19 [?] RSPM (R 4.4.1)\n P evaluate      1.0.3   2025-01-10 [?] RSPM\n P fastmap       1.2.0   2024-05-15 [?] RSPM (R 4.4.1)\n P htmltools     0.5.8.1 2024-04-04 [?] RSPM (R 4.4.1)\n P jsonlite      1.8.9   2024-09-20 [?] RSPM\n P knitr         1.49    2024-11-08 [?] RSPM (R 4.4.2)\n   renv          1.1.1   2025-02-07 [1] RSPM (R 4.4.0)\n P rlang         1.1.5   2025-01-17 [?] RSPM\n P rmarkdown     2.29    2024-11-04 [?] RSPM (R 4.4.2)\n P sessioninfo   1.2.3   2025-02-05 [?] RSPM\n P xfun          0.50    2025-01-07 [?] RSPM\n P yaml          2.3.10  2024-07-26 [?] RSPM (R 4.4.1)\n\n [1] /media/LaCie16TB/work/projects/documentation/read_rs_product/renv/library/linux-linuxmint-noble/R-4.4/x86_64-pc-linux-gnu\n [2] /home/filoche/.cache/R/renv/sandbox/linux-linuxmint-noble/R-4.4/x86_64-pc-linux-gnu/9a444a72\n\n P ── Loaded and on-disk path mismatch.\n\n──────────────────────────────────────────────────────────────────────────────",
    "crumbs": [
      "Additional Resources"
    ]
  }
]